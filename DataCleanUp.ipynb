{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1. Importing and cleaning the data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "\n",
    "# Import for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import custom functions\n",
    "import bb_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This analysis is done year by year\n",
    "# Setting up parameters\n",
    "# Set directories and other file parameters\n",
    "main_dir = os.getcwd() \n",
    "data_dir = main_dir + '/data'\n",
    "filename_pre = 'indego_trips_'\n",
    "file_format = '.csv'\n",
    "year_range = ['2015','2016','2017','2018'] \n",
    "column_names = ['trip_id', 'duration', 'start_time', 'end_time','start_station','start_lat','start_lon', \n",
    "                    'end_station','end_lat','end_lon', 'bike_id', 'plan_duration', 'trip_route_category', 'passholder_type']\n",
    "which_year = '2015'\n",
    "which_ride_end = 'end'\n",
    "station_numbers = [3000, 4000] # exclude dummy stations\n",
    "min_duration = 1 # 1 minute\n",
    "max_duration_sd = 2 # 2 standard deviations \n",
    "\n",
    "# Parameters for identifying valuable stations\n",
    "how_many = 11\n",
    "inactive = 3023\n",
    "\n",
    "# Option to look at the breakdown of passholder types: overall and per station\n",
    "passholders_per_station = False\n",
    "passholders = False \n",
    "\n",
    "######################\n",
    "\n",
    "# Import and clean data\n",
    "filenames = bb_clean_data.get_filenames_year(which_year, filename_pre, file_format)\n",
    "df = bb_clean_data.create_and_clean_df(which_year, filenames, data_dir, column_names, \n",
    "                                       min_duration, max_duration_sd, station_numbers)\n",
    "\n",
    "# Get the data and save them for analyzing the rides over time (rides aggregated by month)\n",
    "df['month'] = pd.DatetimeIndex(df['start_time']).month\n",
    "if which_year == '2018':\n",
    "    df = df[df['month'] < 10] # before october\n",
    "elif which_year == '2015': \n",
    "    df = df[df['month'] > 4] # after april\n",
    "rides_per_month = df.groupby('month').count()['trip_id']\n",
    "filename = 'rides_per_month'+ str(which_year) + '.pckl'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(rides_per_month, f)\n",
    "f.close()\n",
    "\n",
    "# Calculate % passholders of different types across the network for a given year\n",
    "if passholders:\n",
    "    passholder_type_agg = df.groupby('passholder_type').count()['trip_id']/sum(df.groupby('passholder_type').count()['trip_id'])\n",
    "    passholder_labels = passholder_type_agg.index.values.tolist()\n",
    "    print(passholder_type_agg)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(passholder_type_agg, labels = passholder_labels, autopct ='%1.1f%%',\n",
    "        shadow = True, startangle = 90)\n",
    "    ax1.axis('equal')  # Note from web: Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()    \n",
    "\n",
    "# Make a timeseries array (this will be the same for start_time and end_time analysis)\n",
    "first_day = df['start_time_date'].min().to_timestamp()\n",
    "last_day = df['start_time_date'].max().to_timestamp() + timedelta(hours=23) # goes until the end of the day\n",
    "timeseries_format =  pd.date_range(first_day, last_day, freq='H')\n",
    "\n",
    "# Identify most valuable stations\n",
    "station_df = df.groupby(['start_station'])['trip_id'].count() #identify unique trips and count them\n",
    "most_valuable_stations = station_df.sort_values(ascending = False).head(how_many).index.tolist()\n",
    "most_valuable_stations.remove(inactive)\n",
    "print(how_many,\"most valuable stations in rank-order are: \", most_valuable_stations)\n",
    "\n",
    "# Save the set of stations if it's for 2018 year\n",
    "if which_year == 2018: \n",
    "    import pickle\n",
    "    f = open('most_valuable_stations.pckl', 'wb')\n",
    "    pickle.dump(most_valuable_stations, f)\n",
    "    f.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load repeating stations \n",
    "# This list is created in a different script and contains info about stations active in 2016, 2017 AND 2018. \n",
    "station_list =  list(pickle.load(open(\"repeating_stations.pckl\",\"rb\")))\n",
    "for station in station_list: \n",
    "    this_station_df = bb_clean_data.join_df_with_timeseries(df, timeseries_format, station, which_ride_end)  \n",
    "    if which_ride_end == 'start':\n",
    "        # Save dataframe into csv file for further analysis\n",
    "        filename = 'intermediate_df/Station'+ str(int(station)) + '-' + which_year + file_format\n",
    "    elif which_ride_end == 'end':\n",
    "        # Save dataframe into csv file for further analysis\n",
    "        filename = 'intermediate_df/EndStation'+ str(int(station)) + '-' + which_year + file_format\n",
    "    this_station_df.to_csv(filename)\n",
    "    del this_station_df \n",
    "    \n",
    "    # Option to look at the breakdown of passholders per station\n",
    "    if passholders_per_station:\n",
    "        st = df[df['start_station_id'] == station] \n",
    "        print(station)\n",
    "        st_passholder_type_agg = st.groupby('passholder_type').count()['trip_id']/sum(st.groupby('passholder_type').count()['trip_id'])\n",
    "        st_passholder_type_agg.round(decimals = 2)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = pd.read_csv('data/indego-stations-2019-01-04.csv').reset_index()\n",
    "stations_dict = {}\n",
    "for station in most_valuable_stations:\n",
    "         #print(stations_df[stations_df['Station ID'] == station]['Station Name']) \n",
    "         stations_dict[station] = stations_df[stations_df['Station ID'] == station]['Station Name'].item()\n",
    "pickle_it = True\n",
    "if pickle_it:\n",
    "    import pickle\n",
    "    f = open('most_valuable_stations_dict.pckl', 'wb')\n",
    "    pickle.dump(stations_dict, f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
