{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and other file parameters\n",
    "main_dir = os.getcwd() \n",
    "data_dir = main_dir + '/data'\n",
    "file_format = '.csv'\n",
    "year_range = ['2015','2016','2017','2018'] \n",
    "column_names = ['trip_id', 'duration', 'start_time', 'end_time','start_station','start_lat','start_lon', \n",
    "                    'end_station','end_lat','end_lon', 'bike_id', 'plan_duration', 'trip_route_category', 'passholder_type']\n",
    "# Get filenames\n",
    "def get_filenames_year(which_year):\n",
    "    if which_year == '2018':\n",
    "        filenames = ['indego_trips_2018_q1'+ file_format, 'indego_trips_2018_q2'+ file_format,\n",
    "                 'indego_trips_2018_q3'+ file_format]\n",
    "    elif which_year == '2017': \n",
    "        filenames = ['indego_trips_2017_q1'+ file_format, 'indego_trips_2017_q2'+ file_format,\n",
    "                 'indego_trips_2017_q3'+ file_format, 'indego_trips_2017_q4'+ file_format]\n",
    "    elif which_year == '2016': \n",
    "        filenames = ['indego_trips_2016_q1'+ file_format, 'indego_trips_2016_q2'+ file_format,\n",
    "                 'indego_trips_2016_q3'+ file_format, 'indego_trips_2016_q4'+ file_format]\n",
    "    elif which_year == '2015': \n",
    "        filenames = ['indego_trips_2015_q2'+ file_format,\n",
    "                 'indego_trips_2015_q3'+ file_format, 'indego_trips_2015_q4'+ file_format]\n",
    "    return filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Loop through all years\n",
    "# 2) Concatinate all quarters for a given year into a single data frame\n",
    "# 3) Clean up: drop rides too short or long. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indego_trips_2015_q2.csv',\n",
       " 'indego_trips_2015_q3.csv',\n",
       " 'indego_trips_2015_q4.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of trips that are too short 1.6.\n",
      "Percent of trips that are too long 1.2.\n",
      "Percent of trips that are too short 1.1.\n",
      "Percent of trips that are too long 1.2.\n",
      "Percent of trips that are too short 0.9.\n",
      "Percent of trips that are too long 1.0.\n"
     ]
    }
   ],
   "source": [
    "filenames = get_filenames_year('2015')\n",
    "def create_and_clean_df(which_year, filenames)    \n",
    "df = pd.DataFrame(columns = column_names)\n",
    "for x in range(len(filenames)): \n",
    "    current_file = os.path.join(data_dir + '/' + filenames[x])\n",
    "    temp = pd.read_csv(current_file)\n",
    "    df = df.append(temp)\n",
    "\n",
    "    # 1) Drop all trips for which there is no duration information\n",
    "    df = df[pd.notnull(df['duration'])]\n",
    "\n",
    "    # 2) Identify potentially anomalous trips (based on length) \n",
    "    maxDuration = df[\"duration\"].mean() + df[\"duration\"].std()*2\n",
    "    minDuration  = 1 #one minute\n",
    "    numDroppedBottom = 100*(len(df[df['duration']<=minDuration]))/(len(df['duration']))\n",
    "    numDroppedTop = 100*(len(df[df['duration']>=maxDuration]))/(len(df['duration']))\n",
    "\n",
    "    # 3) Drop outliers within a q(and print proportions)\n",
    "    df = df[(df.duration < maxDuration) & (df.duration > minDuration)]\n",
    "    print(\"Percent of trips that are too short %0.1f.\" %numDroppedBottom)\n",
    "    print(\"Percent of trips that are too long %0.1f.\" %numDroppedTop)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up based on start station missing data\n",
    "\n",
    "# 1) Drop all trips for which there is no duration information\n",
    "df = df[pd.notnull(df['start_station'])]\n",
    "\n",
    "# Drop all trips for which we don't have the station number. \n",
    "# Identify unknown stations and drop them\n",
    "df['start_station_id'] = df['start_station'].astype(int)\n",
    "df['end_station_id'] = df['end_station'].astype(int)\n",
    "\n",
    "df = df[(df.start_station_id > 3000) & (df.start_station_id < 4000)]\n",
    "df = df[(df.end_station_id > 3000) & (df.end_station_id < 4000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the starttime, so that its rounder per hour\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['start_time'] = df['start_time'].dt.round(\"H\")\n",
    "# Extract date and hour from the start date to end date range\n",
    "df['start_time_date'] = pd.to_datetime(df['start_time']).dt.to_period('D')\n",
    "df['start_time_hour'] = pd.DatetimeIndex(df['start_time']).hour\n",
    "\n",
    "# Reformat the endtime, so that its rounder per hour\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "df['end_time'] = df['end_time'].dt.round(\"H\")\n",
    "# Extract date and hour from the start date to end date range\n",
    "df['end_time_date'] = pd.to_datetime(df['end_time']).dt.to_period('D')\n",
    "df['end_time_hour'] = pd.DatetimeIndex(df['end_time']).hour\n",
    "\n",
    "first_day = df['start_time_date'].min().to_timestamp()\n",
    "last_day = df['start_time_date'].max().to_timestamp()\n",
    "timeseries_format =  pd.date_range(first_day, last_day, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a timeseries dataframe so we can join it with the trips\n",
    "timeseries_columns = ['start_time_date', 'start_time_hour']\n",
    "timeseries_df = pd.DataFrame(index=timeseries_format, columns=timeseries_columns).reset_index()\n",
    "timeseries_columns.insert(0, 'timestamp')\n",
    "timeseries_df.columns = timeseries_columns\n",
    "timeseries_df['start_time_date'] = pd.to_datetime(timeseries_df['timestamp']).dt.to_period('D')\n",
    "timeseries_df['start_time_hour'] = pd.DatetimeIndex(timeseries_df['timestamp']).hour\n",
    "# drop timestamp, we don't need it anymore\n",
    "timeseries_df = timeseries_df.drop(columns = 'timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries(timeseries, column_names): \n",
    "# for end time\n",
    "# format a timeseries dataframe so we can join it with the trips\n",
    "    first_col = column_names[0]\n",
    "    second_col = column_names[1]\n",
    "    t_df = pd.DataFrame(index=timeseries_format, columns=column_names).reset_index()\n",
    "    column_names.insert(0, 'timestamp')\n",
    "    t_df.columns = column_names\n",
    "    t_df[first_col] = pd.to_datetime(t_df['timestamp']).dt.to_period('D')\n",
    "    t_df[second_col] = pd.DatetimeIndex(t_df['timestamp']).hour\n",
    "    # drop timestamp, we don't need it anymore\n",
    "    t_df = t_df.drop(columns = 'timestamp')\n",
    "    return t_df           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_columns = ['end_time_date', 'end_time_hour']\n",
    "timeseries_end_df = make_timeseries(timeseries_format, end_columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify most valuable stations\n",
    "station_df = df.groupby(['start_station'])['trip_id'].count() #identify unique trips and count them\n",
    "how_many = 10\n",
    "most_valuable_stations = station_df.sort_values(ascending = False).head(how_many).index.tolist()\n",
    "print(how_many,\"most valuable stations in rank-order are: \", most_valuable_stations)\n",
    "\n",
    "station_end_df = df.groupby(['end_station'])['trip_id'].count() #identify unique trips and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulatedf(this_df, timeseries, which_station, which_year): \n",
    "    temp_df = this_df[this_df['start_station_id'] == which_station].reset_index()\n",
    "    temp_df = temp_df.drop(columns = 'index')\n",
    "    df = pd.DataFrame({'count':temp_df.groupby(['start_time']).size()}).reset_index()\n",
    "    df = df.set_index('start_time')\n",
    "    df = df.reindex(timeseries, fill_value = 0)\n",
    "    # add date and time separately as columns\n",
    "    # make a column out of an index\n",
    "    df['timestamp'] = df.index\n",
    "    df['start_time_date'] = pd.to_datetime(df['timestamp']).dt.to_period('D')\n",
    "    df['start_time_hour'] = pd.DatetimeIndex(df['timestamp']).hour\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns = 'index')    \n",
    "    # save into dataframe\n",
    "    filename = 'Station'+ str(int(which_station)) + '-' + which_year + file_format\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in most_valuable_stations: \n",
    "    manipulatedf(df, timeseries_format, station, which_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_year == 2018: \n",
    "    import pickle\n",
    "    f = open('most_valuable_stations.pckl', 'wb')\n",
    "    pickle.dump(most_valuable_stations, f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
