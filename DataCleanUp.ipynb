{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "main_dir = os.getcwd() \n",
    "data_dir = main_dir + '/raw_data'\n",
    "\n",
    "# Set files to import\n",
    "which_year = '2017'\n",
    "if which_year == '2018':\n",
    "    filenames = ['indego_trips_2018_q1', 'indego_trips_2018_q2',\n",
    "                 'indego_trips_2018_q3']\n",
    "elif which_year == '2017': \n",
    "    filenames = ['indego_trips_2017_q1', 'indego_trips_2017_q2',\n",
    "             'indego_trips_2017_q3', 'indego_trips_2017_q4']\n",
    "elif which_year == '2016': \n",
    "    filenames = ['indego_trips_2016_q1', 'indego_trips_2016_q2',\n",
    "             'indego_trips_2016_q3', 'indego_trips_2016_q4']\n",
    "column_names = ['trip_id', 'duration', 'start_time', 'end_time','start_station','start_lat','start_lon', \n",
    "                'end_station','end_lat','end_lon', 'bike_id', 'plan_duration', 'trip_route_category', 'passholder_type']\n",
    "file_format = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate all quarters for a given year into a single data frame\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "for x in range(len(filenames)): \n",
    "    current_file = os.path.join(data_dir + '/' + filenames[x] + file_format)\n",
    "    temp = pd.read_csv(current_file)\n",
    "    df = df.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of trips that are too short 1.3.\n",
      "Percent of trips that are too long 1.2.\n"
     ]
    }
   ],
   "source": [
    "# Clean up based on duration\n",
    "\n",
    "# 1) Drop all trips for which there is no duration information\n",
    "df = df[pd.notnull(df['duration'])]\n",
    "\n",
    "# 2) Identify potentially anomalous trips (based on length) \n",
    "maxDuration = df[\"duration\"].mean() + df[\"duration\"].std()*2\n",
    "minDuration  = 1 #one minute\n",
    "numDroppedBottom = 100*(len(df[df['duration']<=minDuration]))/(len(df['duration']))\n",
    "numDroppedTop = 100*(len(df[df['duration']>=maxDuration]))/(len(df['duration']))\n",
    "\n",
    "# 3) Drop outliers (and print proportions)\n",
    "df = df[(df.duration < maxDuration) & (df.duration > minDuration)]\n",
    "print(\"Percent of trips that are too short %0.1f.\" %numDroppedBottom)\n",
    "print(\"Percent of trips that are too long %0.1f.\" %numDroppedTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up based on start station missing data\n",
    "\n",
    "# 1) Drop all trips for which there is no duration information\n",
    "df = df[pd.notnull(df['start_station'])]\n",
    "\n",
    "# Drop all trips for which we don't have the station number. \n",
    "# Identify unknown stations and drop them\n",
    "df['start_station_id'] = df['start_station'].astype(int)\n",
    "df = df[(df.start_station_id > 3000) & (df.start_station_id < 4000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the starttime, so that its rounder per hour\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['start_time'] = df['start_time'].dt.round(\"H\")\n",
    "# Extract date and hour from the start date to end date range\n",
    "df['start_time_date'] = pd.to_datetime(df['start_time']).dt.to_period('D')\n",
    "df['start_time_hour'] = pd.DatetimeIndex(df['start_time']).hour\n",
    "#df['start_time'] = df['start_time'].dt.round(\"H\")\n",
    "first_day = df['start_time_date'].min().to_timestamp()\n",
    "last_day = df['start_time_date'].max().to_timestamp()\n",
    "timeseries =  pd.date_range(first_day, last_day, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a timeseries dataframe so we can join it with the trips\n",
    "timeseries_columns = ['start_time_date', 'start_time_hour']\n",
    "timeseries_df = pd.DataFrame(index=timeseries, columns=timeseries_columns).reset_index()\n",
    "timeseries_columns.insert(0, 'timestamp')\n",
    "timeseries_df.columns = timeseries_columns\n",
    "timeseries_df['start_time_date'] = pd.to_datetime(timeseries_df['timestamp']).dt.to_period('D')\n",
    "timeseries_df['start_time_hour'] = pd.DatetimeIndex(timeseries_df['timestamp']).hour\n",
    "# drop timestamp, we don't need it anymore\n",
    "timeseries_df = timeseries_df.drop(columns = 'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most valuable stations in rank-order are:  [3023, 3010, 3021, 3045, 3032, 3054, 3020, 3012, 3022, 3057]\n"
     ]
    }
   ],
   "source": [
    "# Identify most valuable stations\n",
    "station_df = df.groupby(['start_station'])['trip_id'].count() #identify unique trips and count them\n",
    "how_many = 10\n",
    "most_valuable_stations = station_df.sort_values(ascending = False).head(how_many).index.tolist()\n",
    "print(how_many,\"most valuable stations in rank-order are: \", most_valuable_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulatedf(this_df, timeseries, which_station, which_year): \n",
    "    temp_df = this_df[this_df['start_station_id'] == which_station].reset_index()\n",
    "    temp_df = temp_df.drop(columns = 'index')\n",
    "    df = pd.DataFrame({'count':temp_df.groupby(['start_time']).size()}).reset_index()\n",
    "    df = df.set_index('start_time')\n",
    "    df = df.reindex(timeseries, fill_value = 0)\n",
    "    # add date and time separately as columns\n",
    "    # make a column out of an index\n",
    "    df['timestamp'] = df.index\n",
    "    df['start_time_date'] = pd.to_datetime(df['timestamp']).dt.to_period('D')\n",
    "    df['start_time_hour'] = pd.DatetimeIndex(df['timestamp']).hour\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns = 'index')    \n",
    "    # save into dataframe\n",
    "    filename = 'Station'+  str(which_station) + '-' + which_year + file_format\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in most_valuable_stations: \n",
    "    manipulated_df = manipulatedf(df, timeseries, station, which_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
