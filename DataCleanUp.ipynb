{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1. Importing and cleaning the data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "\n",
    "# Import for plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import custom functions\n",
    "import bb_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ana/anaconda3/envs/insight/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For year 2015: \n",
      "Percent of trips that are too short 1.7.\n",
      "Percent of trips that are too long 1.7.\n",
      "10 most valuable stations in rank-order are:  [3023, 3010, 3045, 3032, 3007, 3022, 3057, 3052, 3021, 3063]\n"
     ]
    }
   ],
   "source": [
    "# Set directories and other file parameters\n",
    "main_dir = os.getcwd() \n",
    "data_dir = main_dir + '/data'\n",
    "filename_pre = 'indego_trips_'\n",
    "file_format = '.csv'\n",
    "year_range = ['2015','2016','2017','2018'] \n",
    "column_names = ['trip_id', 'duration', 'start_time', 'end_time','start_station','start_lat','start_lon', \n",
    "                    'end_station','end_lat','end_lon', 'bike_id', 'plan_duration', 'trip_route_category', 'passholder_type']\n",
    "which_year = '2015'\n",
    "station_numbers = [3000, 4000] # REVISIT THIS TO EXCLUDE DUMMY STATIONS (very few and likely no rides)\n",
    "min_duration = 1 # 1 minute\n",
    "max_duration_sd = 2 # 2 standard deviations \n",
    "\n",
    "filenames = bb_clean_data.get_filenames_year(which_year, filename_pre, file_format)\n",
    "df = bb_clean_data.create_and_clean_df(which_year, filenames, data_dir, column_names, min_duration, max_duration_sd)\n",
    "\n",
    "# Get the data and save them for analyzing the rides over time (aggregated by month)\n",
    "df['month'] = pd.DatetimeIndex(df['start_time']).month\n",
    "if which_year == '2018':\n",
    "    df = df[df['month'] < 10] # before october\n",
    "elif which_year == '2015': \n",
    "    df = df[df['month'] > 4] # after april\n",
    "rides_per_month = df.groupby('month').count()['trip_id']\n",
    "filename = 'rides_per_month'+ str(which_year) + '.pckl'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(rides_per_month, f)\n",
    "f.close()\n",
    "\n",
    "# Calculate % passholders of different types across the network for this year\n",
    "passholders = False \n",
    "if passholders:\n",
    "    passholder_type_agg = df.groupby('passholder_type').count()['trip_id']/sum(df.groupby('passholder_type').count()['trip_id'])\n",
    "    passholder_labels = passholder_type_agg.index.values.tolist()\n",
    "    print(passholder_type_agg)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(passholder_type_agg, labels = passholder_labels, autopct ='%1.1f%%',\n",
    "        shadow = True, startangle = 90)\n",
    "    ax1.axis('equal')  # Note from web: Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()    \n",
    "\n",
    "# Make a timeseries array\n",
    "first_day = df['start_time_date'].min().to_timestamp()\n",
    "last_day = df['start_time_date'].max().to_timestamp()  + timedelta(hours=23)\n",
    "timeseries_format =  pd.date_range(first_day, last_day, freq='H')\n",
    "\n",
    "# Identify most valuable stations\n",
    "how_many = 10\n",
    "station_df = df.groupby(['start_station'])['trip_id'].count() #identify unique trips and count them\n",
    "most_valuable_stations = station_df.sort_values(ascending = False).head(how_many).index.tolist()\n",
    "print(how_many,\"most valuable stations in rank-order are: \", most_valuable_stations)\n",
    "\n",
    "# Save the set of stations if it's for 2018 year\n",
    "if which_year == 2018: \n",
    "    import pickle\n",
    "    f = open('most_valuable_stations.pckl', 'wb')\n",
    "    pickle.dump(most_valuable_stations, f)\n",
    "    f.close()\n",
    "    \n",
    "# Option to look at the breakdown of passholders per station\n",
    "passholders_per_station = False\n",
    "for station in most_valuable_stations: \n",
    "    bb_clean_data.join_df_with_timeseries(df, timeseries_format, station, which_year, file_format)   \n",
    "    if passholders_per_station:\n",
    "        st = df[df['start_station_id'] == station] \n",
    "        print(station)\n",
    "        st_passholder_type_agg = st.groupby('passholder_type').count()['trip_id']/sum(st.groupby('passholder_type').count()['trip_id'])\n",
    "        st_passholder_type_agg.round(decimals = 2)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
