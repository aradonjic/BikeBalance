{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run decision tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualisation  \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns\n",
    "# For modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from math import sqrt \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "# For dates\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "# For holidays\n",
    "import holidays\n",
    "import pickle\n",
    "# Import stuff for modeling\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set modeling parametes\n",
    "# old station_list  = ['3010', '3021', '3054', '3023', '3045']\n",
    "station_list =  list(pickle.load(open(\"repeating_stations.pckl\",\"rb\")))\n",
    "\n",
    "# Get a list of inactive stations. Eliminate them from the list\n",
    "stations_df = pd.read_csv('data/indego-stations-2019-01-04.csv').reset_index()\n",
    "inactive_list = stations_df[stations_df['Status'] == 'Inactive']['Station ID'].values.tolist()\n",
    "\n",
    "year_range = [2016, 2017, 2018]\n",
    "predict = 'count'\n",
    "r_end = 'start'\n",
    "training_end_date = \"15/05/2018\"\n",
    "test_start_date = \"01/07/2018\"\n",
    "start_features = ['temperature', 'humidity', 'precipIntensity', 'windBearing', 'windSpeed',  'snow', 'rain', \n",
    "                  'is_weekday_corrected', 'midday', 'night', 'rushE', 'rushM'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(which_station, year_range, training_end_date, test_start_date, start_features, predict, r_end):\n",
    "    print('Station %s:' %which_station)\n",
    "    # Aggregate data across years\n",
    "    for item in year_range: \n",
    "        filename = 'intermediate_df/Full' + r_end + 'Station' + which_station + '-' + str(item) + '.csv'\n",
    "        if item == year_range[0]:\n",
    "            main_df = pd.read_csv(filename)\n",
    "        else: \n",
    "            temp_df = pd.read_csv(filename)\n",
    "            main_df = main_df.append(temp_df)     \n",
    "    # Split\n",
    "    training_end_date = dt.strptime(training_end_date, \"%d/%m/%Y\")\n",
    "    test_start_date = dt.strptime(test_start_date, \"%d/%m/%Y\")\n",
    "    training_df  = main_df[pd.to_datetime(main_df['date_time']) <= training_end_date].reset_index()\n",
    "    test_df  = main_df[pd.to_datetime(main_df['date_time']) >= test_start_date].reset_index()\n",
    "    test_df.head()\n",
    "    X_train = training_df[start_features] #'which_holiday', \n",
    "    y_train = training_df[[predict]]\n",
    "    X_test = test_df[start_features]\n",
    "    y_test = test_df[[predict]]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "                                                           \n",
    "def fit_model_to_station(X_train, y_train, X_test, y_test, max_depth_range, print_results): \n",
    "    model_type = DecisionTreeRegressor(random_state = 0)\n",
    "    param_grid = dict(max_depth = max_depth_range)\n",
    "    time_series_cv = TimeSeriesSplit(n_splits = 3).split(X_train)\n",
    "    grid_search = GridSearchCV(model_type, param_grid, n_jobs = -1, cv = time_series_cv, verbose = 0, scoring = 'neg_mean_absolute_error')\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    model = DecisionTreeRegressor(max_depth = grid_result.best_params_['max_depth']).fit(X_train, y_train)\n",
    "    model = model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = predictions.round()\n",
    "    \n",
    "    # Baseline model\n",
    "    baseline_model = round(y_test['count'].mean())\n",
    "    baseline_model_pred = np.full_like(y_test.round(), baseline_model)\n",
    "            \n",
    "    if print_results: \n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        print(\"Accuracy on training set: {:.3f}\".format(model.score(X_train, y_train)))\n",
    "        print(\"Accuracy on test set: {:.3f}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "        # Print some diagnostics\n",
    "        print('  Model diagnostics: ')\n",
    "        print('\\tMSE: %0.2f' %np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "        print('\\tRMSE: %0.2f' %metrics.mean_squared_error(y_test, predictions))\n",
    "        print('\\tR^2:  %0.2f' %metrics.r2_score(y_test, predictions))\n",
    "        \n",
    "        # Print diagnostics on baseline\n",
    "        print('  Baseline model:')\n",
    "        print('\\tMSE: %0.2f' %metrics.mean_squared_error(y_test, baseline_model_pred))\n",
    "        print('\\tRMSE: %0.2f' %np.sqrt(metrics.mean_squared_error(y_test, baseline_model_pred)))\n",
    "        print('\\tR^2: %0.2f' %metrics.r2_score(y_test, baseline_model_pred))\n",
    "    return model, predictions, baseline_model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1, 15, 2)\n",
    "pickle_it  = True \n",
    "print_results = True\n",
    "criterion = 0\n",
    "correct_model = []\n",
    "correct_baseline = []\n",
    "numbers_train = []\n",
    "numbers_test = []\n",
    "station_name = []\n",
    "station_number = []\n",
    "# Get a list of inactive stations. Eliminate them from the list\n",
    "stations_df = pd.read_csv('data/indego-stations-2019-01-04.csv').reset_index()\n",
    "inactive_list = stations_df[stations_df['Status'] == 'Inactive']['Station ID'].values.tolist()\n",
    "\n",
    "for which_station in station_list: \n",
    "    which_station = str(which_station)\n",
    "    which_station = which_station[:-2]\n",
    "    # check that the station is active and only run the model if it is\n",
    "    if int(which_station) not in inactive_list: \n",
    "        X_train, y_train, X_test, y_test = get_train_test_data(which_station, year_range, \n",
    "                                training_end_date, test_start_date, start_features, predict, r_end)\n",
    "        model, predictions, baseline_pred = fit_model_to_station(X_train, y_train, X_test, y_test, \n",
    "                   max_depth_range, print_results)\n",
    "        # Pickle model\n",
    "        if pickle_it: \n",
    "            pickled_model_name = r_end + '_dt_model' + which_station + '.pckl'\n",
    "            f = open(pickled_model_name, 'wb')\n",
    "            pickle.dump(model, f)\n",
    "            f.close()    \n",
    "        # load each model, then estimate accuracy\n",
    "        y_test_df = y_test\n",
    "        y_test_df['model_pred'] = predictions\n",
    "        y_test['model_dev'] = y_test_df['count']-y_test_df['model_pred']\n",
    "        y_test['model_correct'] = y_test['model_dev'] <= np.absolute(criterion)\n",
    "\n",
    "        y_test_df['baseline_pred'] = baseline_pred\n",
    "        y_test['baseline_dev'] = y_test_df['count']-y_test_df['baseline_pred']\n",
    "        y_test['baseline_correct'] = y_test['baseline_dev'] <= np.absolute(criterion)\n",
    "        percent_correct_model = y_test['model_correct'].sum()/len(y_test)\n",
    "        percent_correct_baseline = y_test['baseline_correct'].sum()/len(y_test)\n",
    "        correct_model.append(percent_correct_model)\n",
    "        correct_baseline.append(percent_correct_baseline)\n",
    "        numbers_train.append(sum(y_train['count']))\n",
    "        numbers_test.append(sum(y_test['count']))\n",
    "        \n",
    "        station_number.append(which_station)\n",
    "        station_name.append(stations_df[stations_df['Station ID'] == int(which_station)]['Station Name'].values[0])\n",
    "        \n",
    "        print((sum(y_train['count']), sum(y_test['count'])))\n",
    "        print('\\tModel is correct %d%% time' %(percent_correct_model*100))\n",
    "        print('\\tBaseline is correct %d%% time' %(percent_correct_baseline*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one model and plot feature importance\n",
    "\n",
    "which_station = 3010\n",
    "filename  = r_end + '_dt_model' + str(which_station) + '.pckl'\n",
    "dt_model = pickle.load(open(filename, 'rb'))\n",
    "features = start_features\n",
    "importances = dt_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "how_many_feat = len(dt_model.feature_importances_[dt_model.feature_importances_>0.03])\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.barh(range(how_many_feat)[::-1], importances[indices][::-1][0:how_many_feat], color = (170/255, 170/255, 170/255))\n",
    "plt.yticks(range(how_many_feat)[::-1], np.array(features)[indices][::-1][0:how_many_feat], fontsize=16)\n",
    "plt.xlabel('Relative Importance',fontsize = 13)\n",
    "plt.xticks(fontsize = 13)\n",
    "plt.savefig(\"feature_importance.pdf\", bbox_inches = 'tight')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.subtract(correct_model,correct_baseline)>0)/len(correct_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the results across the stations. \n",
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['st_num'] = station_number\n",
    "results['st_name'] = station_name\n",
    "results['n_test'] = numbers_test\n",
    "results['n_train'] = numbers_train\n",
    "results['per_correct_model'] = correct_model\n",
    "results['per_correct_baseline'] = correct_baseline\n",
    "results['percent_test'] = np.divide(numbers_test,np.add(numbers_test,numbers_train))*100\n",
    "results['equal'] = (results['per_correct_model'] == results['per_correct_baseline'])\n",
    "results['difference'] = np.subtract(correct_model,correct_baseline)*100\n",
    "\n",
    "results = results[results['st_name']!=\"Virtual Station\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('ResultsStartRides.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify stations with very sparse data\n",
    "at_least_six_a_day = 92*6\n",
    "sparse_df = results[(results.n_test) <= at_least_six_a_day]\n",
    "not_sparse_df = results[(results.n_test) > at_least_six_a_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_sparse_df[not_sparse_df.per_correct_model > not_sparse_df.per_correct_baseline])/len(not_sparse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_sparse_df[not_sparse_df.per_correct_model > not_sparse_df.per_correct_baseline])/len(not_sparse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_sparse_worse  = not_sparse_df[not_sparse_df.per_correct_model < not_sparse_df.per_correct_baseline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of the model vs. baseline for stations where the data is not sparse\n",
    "not_sparse_df['per_correct_baseline'].plot.hist(10)\n",
    "not_sparse_df['per_correct_model'].plot.hist(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot summary results (model vs. baseline)\n",
    "marker_size = 12\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "ax = plt.plot(results['per_correct_baseline'], results['per_correct_model'], 'o',\n",
    "              color = (33/255, 131/255, 200/255), markersize = marker_size)\n",
    "ax = plt.plot(sparse_df['per_correct_baseline'], sparse_df['per_correct_model'], 'o', markersize = marker_size,  \n",
    "             color = '#98D734')\n",
    "ax = plt.plot(not_sparse_worse['per_correct_baseline'], not_sparse_worse['per_correct_model'], 'o', markersize = marker_size, \n",
    "             color = '#CA3433')\n",
    "plt.plot([0,1],[0,1], '-', color = 'k')\n",
    "plt.xlim(0.5,1)\n",
    "plt.ylim(0.5,1)\n",
    "plt.xlabel('Baseline Accuracy (%)',fontsize = 15)\n",
    "plt.ylabel('Model Accuracy (%)',fontsize = 15)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.savefig(\"model_baseline_0_blue.pdf\", bbox_inches = 'tight')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with visualizing decision trees\n",
    "which_station = 3010\n",
    "filename  = r_end + '_dt_model' + str(which_station) + '.pckl'\n",
    "dt_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "\n",
    "from IPython.display import Image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt_model, out_file=None, \n",
    "                                feature_names=start_features)\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "graph.create_png()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
