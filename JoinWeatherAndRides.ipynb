{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3. Clean and decode weather and rides data and join them together </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "# For dates\n",
    "from datetime import datetime as dta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "            \n",
    "# Import custom functions\n",
    "import bb_modify_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_rides_and_weather(rides_filename, weather_filename, which_end):\n",
    "    # read data into dataframe\n",
    "    rides_df = pd.read_csv(rides_filename)\n",
    "    weather_df = pd.read_csv(weather_filename)\n",
    "    # shape columns for join for rides data\n",
    "    if which_end == 'Start':\n",
    "        rides_df['hour'] = rides_df['start_time_hour']\n",
    "        rides_df['date'] = pd.to_datetime(rides_df['start_time_date']) \n",
    "    elif which_end == 'End':    \n",
    "        rides_df['hour'] = rides_df['end_time_hour']\n",
    "        rides_df['date'] = pd.to_datetime(rides_df['end_time_date']) \n",
    "    rides_df.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "    # convert weather data to dates for joining\n",
    "    weather_df['date'] = pd.to_datetime(weather_df['date_time'])\n",
    "    # Merge\n",
    "    new_df = pd.merge(rides_df, weather_df, on = ['date', 'hour'])\n",
    "    new_df = new_df.dropna(subset = ['temperature', 'humidity', 'precipIntensity', \n",
    "                                     'windBearing', 'windSpeed'])\n",
    "    \n",
    "    # Analysis of strike data\n",
    "    if which_year == '2016': \n",
    "        start_from_temp = \"24/10/2016\"\n",
    "        end_at_temp = \"14/11/2016\"\n",
    "        start_from = dta.strptime(start_from_temp, \"%d/%m/%Y\")\n",
    "        end_at = dta.strptime(end_at_temp, \"%d/%m/%Y\")\n",
    "        strike_df  = new_df[(pd.to_datetime(new_df['date_time']) > start_from) & \n",
    "                          (pd.to_datetime(new_df['date_time']) <= end_at)].reset_index()\n",
    "        if which_end == 'Start':\n",
    "            strike_trips = strike_df.groupby(['start_time_date'])['count'].sum()\n",
    "        elif which_end == 'End':\n",
    "            strike_trips = strike_df.groupby(['end_time_date'])['count'].sum()\n",
    "        \n",
    "        thisMax = strike_trips.max()\n",
    "\n",
    "        plot_fig = False\n",
    "        if plot_fig == True: \n",
    "            # this is the public strike week. We can plot the spike in demand for this week. \n",
    "            # Based on this spike we decide to drop this week. \n",
    "            f = plt.figure()\n",
    "            plt.plot(strike_trips, 'o', color = (178/255, 34/255, 34/255))\n",
    "            plt.xlabel('dates')\n",
    "            plt.ylabel('nTrips')\n",
    "            ax = plt.gca()\n",
    "            x_labels = ax.get_xticks()\n",
    "            ax.set_xticklabels(['25T', '26W','27T', '28F', '29S', '30S', '31M',\n",
    "                        '1T', '2W', '3T', '4F', '5S', '6S', '7M', \n",
    "                        '8T', '9W', '10T', '11F', '12S', '13S', '13M'])\n",
    "            plt.plot([6.5, 6.5], [0, 140], color='k', linestyle='--', linewidth=2)\n",
    "            plt.plot([13.5, 13.5], [0, 140], color='k', linestyle='--', linewidth=2)\n",
    "            plt.ylim([0, thisMax+10])\n",
    "            plt.show()\n",
    "            f.savefig(\"strike.pdf\", bbox_inches = 'tight')\n",
    "\n",
    "        strike_start_temp = \"1/11/2016\"\n",
    "        strike_end_temp = \"7/11/2016\"\n",
    "        strike_start = dta.strptime(strike_start_temp, \"%d/%m/%Y\")\n",
    "        strike_end = dta.strptime(strike_end_temp, \"%d/%m/%Y\")\n",
    "        new_df  = new_df[(pd.to_datetime(new_df['date_time']) < strike_start) | \n",
    "                          (pd.to_datetime(new_df['date_time']) > strike_end)].reset_index() \n",
    "        new_df.drop(['index'], axis=1, inplace = True) \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rides for a given year\n",
    "year_list = ['2016', '2017', '2018']\n",
    "ride_ends = ['Start', 'End']\n",
    "#most_valuable_stations = ['3010', '3021', '3054', '3023', '3045']\n",
    "station_list =  list(pickle.load(open(\"repeating_stations.pckl\",\"rb\")))\n",
    "file_format = '.csv'\n",
    "save_df = True\n",
    "directory = 'intermediate_df/'\n",
    "# first modify weather data\n",
    "for which_year in year_list:\n",
    "    weather_filename = 'intermediate_df/Weather' + which_year + file_format\n",
    "    weather_df = pd.read_csv(weather_filename)\n",
    "    complete_weather_df = bb_modify_weather.get_weather_df(weather_df)\n",
    "    if save_df == True:\n",
    "        new_weather_filename = 'intermediate_df/CompleteWeather'  + which_year + file_format\n",
    "        complete_weather_df.to_csv(new_weather_filename)\n",
    "    del complete_weather_df   \n",
    "        \n",
    "for which_year in year_list: \n",
    "    for which_station in station_list:\n",
    "        for r_end in ride_ends: \n",
    "        # write to new dataframe\n",
    "            if r_end == 'Start':\n",
    "                rides_filename = directory + 'Station' + str(int(which_station)) + '-' + which_year + file_format\n",
    "            elif r_end == 'End':\n",
    "                rides_filename = directory + r_end + 'Station' + str(int(which_station)) + '-' + which_year + file_format\n",
    "            weather_filename = 'intermediate_df/CompleteWeather'  + which_year + file_format\n",
    "            station_weather_df = join_rides_and_weather(rides_filename, weather_filename, r_end)\n",
    "            station_weather_filename = 'intermediate_df/Full' + r_end + 'Station' + str(int(which_station)) + '-' + which_year + file_format\n",
    "            station_weather_df.to_csv(station_weather_filename)\n",
    "            del station_weather_df              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
